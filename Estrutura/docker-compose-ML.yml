services:
  ollama-ml:
    container_name: ollama-ml
    image: ollama/ollama:0.5.12-rocm
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 6g
    ports:
      - "10012:11434"
