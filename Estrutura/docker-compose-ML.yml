services:
  ollama-ml:
    container_name: ollama-ml
    image: ollama/ollama:0.5.12-rocm
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4g
    ports:
      - "10012:11434"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:10012/health"]
      interval: 10s
      timeout: 5s
      retries: 5