services:
  ollama-ml:
    container_name: ollama-ml
    image: ollama/ollama:0.5.12-rocm
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4g
    ports:
      - "10012:11434"
      